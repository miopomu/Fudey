import UIKit
import Vision

/// å†™çœŸã‹ã‚‰æ–‡å­—ã‚’èªè­˜ã™ã‚‹ã‚¯ãƒ©ã‚¹
class PhotoAnalyzer {

    // MARK: - Properties

    static let shared = PhotoAnalyzer()

    private init() {}

    // MARK: - Public Methods

    /// ç”»åƒã‹ã‚‰æ–‡å­—ã‚’èªè­˜ã™ã‚‹
    /// - Parameters:
    ///   - image: è§£æã™ã‚‹ç”»åƒ
    ///   - completion: å®Œäº†ãƒãƒ³ãƒ‰ãƒ©ï¼ˆèªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã€ã‚¨ãƒ©ãƒ¼ï¼‰
    func recognizeText(from image: UIImage, completion: @escaping (Result<[RecognizedText], Error>) -> Void) {
        print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        print("ğŸ” OCRé–‹å§‹ (recognizeText)")

        guard let cgImage = image.cgImage else {
            print("âŒ CGImageå¤‰æ›å¤±æ•—")
            completion(.failure(PhotoAnalyzerError.invalidImage))
            return
        }

        print("âœ… ç”»åƒã‚µã‚¤ã‚º: \(cgImage.width) x \(cgImage.height)")

        // Vision ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä½œæˆ
        let request = VNRecognizeTextRequest { request, error in
            if let error = error {
                print("âŒ Visionå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: \(error)")
                completion(.failure(error))
                return
            }

            guard let observations = request.results as? [VNRecognizedTextObservation] else {
                print("âŒ çµæœãŒnil")
                completion(.failure(PhotoAnalyzerError.noTextFound))
                return
            }

            print("ğŸ“Š èªè­˜ã•ã‚ŒãŸé ˜åŸŸæ•°: \(observations.count)")

            if observations.isEmpty {
                print("âš ï¸ èªè­˜çµæœãŒ0ä»¶")
                print("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: ç”»åƒãŒæš—ã™ãã‚‹ã€ã¾ãŸã¯æ–‡å­—ãŒå°ã•ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
                completion(.failure(PhotoAnalyzerError.noTextFound))
                return
            }

            // ã™ã¹ã¦ã®å€™è£œã‚’è©³ç´°è¡¨ç¤º
            for (index, observation) in observations.enumerated() {
                print("\nğŸ“ é ˜åŸŸ \(index + 1):")
                print("   å¢ƒç•Œ: \(observation.boundingBox)")

                let candidates = observation.topCandidates(10)  // 10å€™è£œè¡¨ç¤º
                print("   å€™è£œæ•°: \(candidates.count)")

                for (i, candidate) in candidates.enumerated() {
                    print("   \(i + 1). [\(candidate.string)] ä¿¡é ¼åº¦: \(String(format: "%.3f", candidate.confidence))")
                }
            }

            // èªè­˜ã•ã‚ŒãŸæ–‡å­—ã‚’å‡¦ç†
            let recognizedTexts = self.processObservations(observations, imageSize: image.size)

            if recognizedTexts.isEmpty {
                print("\nâš ï¸ processObservationså¾Œã®çµæœãŒ0ä»¶ï¼ˆä¿¡é ¼åº¦ãƒ•ã‚£ãƒ«ã‚¿ã§é™¤å¤–ã•ã‚ŒãŸå¯èƒ½æ€§ï¼‰")
                completion(.failure(PhotoAnalyzerError.noTextFound))
            } else {
                print("\nâœ… æœ€çµ‚çµæœ: \(recognizedTexts.count)ä»¶ã®æ–‡å­—ã‚’èªè­˜")
                completion(.success(recognizedTexts))
            }

            print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        }

        // âœ… é‡è¦: ã™ã¹ã¦ã®è¨€èªã‚’è©¦ã™
        let languages = ["ja", "en", "zh-Hans", "zh-Hant"]
        request.recognitionLanguages = languages
        print("ğŸŒ èªè­˜è¨€èª: \(languages)")

        request.recognitionLevel = .accurate
        request.usesLanguageCorrection = true
        request.minimumTextHeight = 0.0  // âœ… æœ€å°ã‚µã‚¤ã‚ºåˆ¶é™ã‚’å®Œå…¨ã«è§£é™¤

        print("âš™ï¸ èªè­˜ãƒ¬ãƒ™ãƒ«: \(request.recognitionLevel)")
        print("âš™ï¸ æœ€å°ãƒ†ã‚­ã‚¹ãƒˆé«˜ã•: \(request.minimumTextHeight)")

        // ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å®Ÿè¡Œ
        let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])

        print("ğŸš€ Visionå®Ÿè¡Œä¸­...")

        DispatchQueue.global(qos: .userInitiated).async {
            do {
                try handler.perform([request])
                print("âœ… Visionå®Ÿè¡Œå®Œäº†")
            } catch {
                print("âŒ Visionå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: \(error)")
                DispatchQueue.main.async {
                    completion(.failure(error))
                }
            }
        }
    }

    /// æœ€ã‚‚å¤§ãã„/ç›®ç«‹ã¤æ–‡å­—ã‚’å–å¾—ï¼ˆæ”¹è‰¯ç‰ˆ - Claude Vision ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãï¼‰
    /// - Parameters:
    ///   - image: è§£æã™ã‚‹ç”»åƒ
    ///   - completion: å®Œäº†ãƒãƒ³ãƒ‰ãƒ©ï¼ˆæœ€ã‚‚ç›®ç«‹ã¤æ–‡å­—ã€ã‚¨ãƒ©ãƒ¼ï¼‰
    func findMainCharacter(from image: UIImage, completion: @escaping (Result<String, Error>) -> Void) {
        print("\nğŸ¯ findMainCharacteré–‹å§‹")

        // æ–¹æ³•1: ã¾ãšVision OCRã‚’è©¦ã™
        recognizeText(from: image) { [weak self] result in
            switch result {
            case .success(let texts):
                print("\nğŸ“ é¢ç©è¨ˆç®—:")
                for (index, text) in texts.enumerated() {
                    let area = text.boundingBox.width * text.boundingBox.height
                    print("   \(index + 1). [\(text.text)] é¢ç©: \(String(format: "%.1f", area)) (ä¿¡é ¼åº¦: \(String(format: "%.3f", text.confidence)))")
                }

                // æœ€ã‚‚å¤§ãã„æ–‡å­—ï¼ˆé¢ç©ãŒæœ€å¤§ï¼‰ã‚’å–å¾—
                if let mainText = texts.max(by: { $0.boundingBox.width * $0.boundingBox.height < $1.boundingBox.width * $1.boundingBox.height }) {
                    let area = mainText.boundingBox.width * mainText.boundingBox.height
                    print("\nâœ… OCRæˆåŠŸ: [\(mainText.text)]")
                    print("   ä¿¡é ¼åº¦: \(String(format: "%.3f", mainText.confidence))")
                    print("   é¢ç©: \(String(format: "%.1f", area))")
                    completion(.success(mainText.text))
                    return
                } else {
                    print("âŒ æœ€å¤§é¢ç©ã®æ–‡å­—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                }

            case .failure(let error):
                print("âŒ recognizeTextå¤±æ•—: \(error.localizedDescription)")
            }

            // æ–¹æ³•2: OCRå¤±æ•— â†’ Claude Vision APIã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            print("âš ï¸ OCRå¤±æ•—ã€Claude Vision APIã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            self?.recognizeWithClaudeVision(image: image, completion: completion)
        }
    }

    /// æœ€ã‚‚å¤§ãã„/ç›®ç«‹ã¤æ–‡å­—ã‚’å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹ä»˜ãã§å–å¾—
    /// - Parameters:
    ///   - image: è§£æã™ã‚‹ç”»åƒ
    ///   - completion: å®Œäº†ãƒãƒ³ãƒ‰ãƒ©ï¼ˆæ–‡å­—ã¨å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹ã€ã‚¨ãƒ©ãƒ¼ï¼‰
    func findMainCharacterWithBounds(from image: UIImage, completion: @escaping (Result<CharacterWithBounds, Error>) -> Void) {
        print("\nğŸ¯ findMainCharacterWithBoundsé–‹å§‹")

        // Vision OCRã‚’è©¦ã™
        recognizeText(from: image) { [weak self] result in
            switch result {
            case .success(let texts):
                print("\nğŸ“ é¢ç©è¨ˆç®—:")
                for (index, text) in texts.enumerated() {
                    let area = text.boundingBox.width * text.boundingBox.height
                    print("   \(index + 1). [\(text.text)] é¢ç©: \(String(format: "%.1f", area)) (ä¿¡é ¼åº¦: \(String(format: "%.3f", text.confidence)))")
                }

                // æœ€ã‚‚å¤§ãã„æ–‡å­—ï¼ˆé¢ç©ãŒæœ€å¤§ï¼‰ã‚’å–å¾—
                if let mainText = texts.max(by: { $0.boundingBox.width * $0.boundingBox.height < $1.boundingBox.width * $1.boundingBox.height }) {
                    let area = mainText.boundingBox.width * mainText.boundingBox.height
                    print("\nâœ… OCRæˆåŠŸ: [\(mainText.text)]")
                    print("   ä¿¡é ¼åº¦: \(String(format: "%.3f", mainText.confidence))")
                    print("   é¢ç©: \(String(format: "%.1f", area))")
                    print("   å¢ƒç•Œ: \(mainText.boundingBox)")

                    let result = CharacterWithBounds(
                        text: mainText.text,
                        boundingBox: mainText.boundingBox
                    )
                    completion(.success(result))
                    return
                } else {
                    print("âŒ æœ€å¤§é¢ç©ã®æ–‡å­—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                }

            case .failure(let error):
                print("âŒ recognizeTextå¤±æ•—: \(error.localizedDescription)")
            }

            // OCRå¤±æ•— â†’ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹ã‚’ä½¿ç”¨ï¼ˆç”»åƒä¸­å¤®60%ï¼‰
            print("âš ï¸ OCRå¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆä¸­å¤®60%ã‚’ä½¿ç”¨ï¼‰")
            self?.recognizeWithClaudeVision(image: image) { visionResult in
                switch visionResult {
                case .success(let text):
                    // å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹ãŒãªã„å ´åˆã¯ç”»åƒä¸­å¤®60%ã‚’ä½¿ç”¨
                    let imageWidth = image.size.width
                    let imageHeight = image.size.height

                    // ä¸­å¤®60%ã®é ˜åŸŸã‚’è¨ˆç®—
                    let centerRatio: CGFloat = 0.6
                    let marginRatio: CGFloat = (1.0 - centerRatio) / 2.0  // 0.2

                    let centerBounds = CGRect(
                        x: imageWidth * marginRatio,
                        y: imageHeight * marginRatio,
                        width: imageWidth * centerRatio,
                        height: imageHeight * centerRatio
                    )

                    print("   ä¸­å¤®é ˜åŸŸ: \(centerBounds)")
                    let result = CharacterWithBounds(text: text, boundingBox: centerBounds)
                    completion(.success(result))
                case .failure(let error):
                    completion(.failure(error))
                }
            }
        }
    }

    /// OpenAI Vision APIã§ç”»åƒã‹ã‚‰æ–‡å­—ã‚’èªè­˜
    private func recognizeWithClaudeVision(image: UIImage, completion: @escaping (Result<String, Error>) -> Void) {
        print("\nğŸ¤– OpenAI Vision APIé–‹å§‹")

        // ç”»åƒã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        guard let imageData = image.jpegData(compressionQuality: 0.8) else {
            print("âŒ ç”»åƒå¤‰æ›å¤±æ•—")
            completion(.failure(PhotoAnalyzerError.invalidImage))
            return
        }

        let base64Image = imageData.base64EncodedString()
        print("âœ… ç”»åƒã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å®Œäº†: \(imageData.count / 1024)KB")

        // APIã‚­ãƒ¼ãƒã‚§ãƒƒã‚¯
        guard let apiKey = ProcessInfo.processInfo.environment["OPENAI_API_KEY"],
              !apiKey.isEmpty else {
            print("âš ï¸ APIã‚­ãƒ¼æœªè¨­å®šã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã—ã¾ã™")
            completion(.success("æ›¸"))  // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            return
        }

        // OpenAI APIãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        guard let url = URL(string: "https://api.openai.com/v1/chat/completions") else {
            completion(.failure(PhotoAnalyzerError.processingFailed))
            return
        }

        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        request.setValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")

        let body: [String: Any] = [
            "model": "gpt-4o-mini",
            "messages": [
                [
                    "role": "user",
                    "content": [
                        [
                            "type": "text",
                            "text": """
ã“ã®ç”»åƒã«æ›¸ã‹ã‚Œã¦ã„ã‚‹æ›¸é“ã®æ¼¢å­—ã‚’1æ–‡å­—ã ã‘èªè­˜ã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦ã€‘
- æ¼¢å­—1æ–‡å­—ã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„
- èª¬æ˜ã‚„å¥èª­ç‚¹ã¯ä¸è¦ã§ã™
- æ‰‹æ›¸ãæ›¸é“ã®æ–‡å­—ã§ã™
- è¤‡é›‘ãªå­—å½¢ã‚„èŠ¸è¡“çš„ãªå´©ã—ã‚‚èªè­˜ã—ã¦ãã ã•ã„

ä¾‹ï¼šæ°´ã€ç«ã€å±±ã€å·ã€æ°¸ã€æ„›ã€é¾ã€é“ ãªã©
"""
                        ],
                        [
                            "type": "image_url",
                            "image_url": [
                                "url": "data:image/jpeg;base64,\(base64Image)"
                            ]
                        ]
                    ]
                ]
            ],
            "max_tokens": 50
        ]

        do {
            request.httpBody = try JSONSerialization.data(withJSONObject: body)
        } catch {
            print("âŒ JSONå¤‰æ›å¤±æ•—: \(error)")
            completion(.failure(error))
            return
        }

        print("ğŸš€ OpenAI Vision APIå®Ÿè¡Œä¸­...")

        // éåŒæœŸãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        let task = URLSession.shared.dataTask(with: request) { data, response, error in
            if let error = error {
                print("âŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: \(error)")
                DispatchQueue.main.async {
                    completion(.failure(error))
                }
                return
            }

            guard let data = data else {
                print("âŒ ãƒ‡ãƒ¼ã‚¿ãªã—")
                DispatchQueue.main.async {
                    completion(.failure(PhotoAnalyzerError.processingFailed))
                }
                return
            }

            // ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‘ãƒ¼ã‚¹
            do {
                if let json = try JSONSerialization.jsonObject(with: data) as? [String: Any],
                   let choices = json["choices"] as? [[String: Any]],
                   let firstChoice = choices.first,
                   let message = firstChoice["message"] as? [String: Any],
                   let content = message["content"] as? String {

                    // 1æ–‡å­—ã ã‘æŠ½å‡ºï¼ˆä½™è¨ˆãªæ–‡å­—ã‚’é™¤å»ï¼‰
                    let cleaned = content.trimmingCharacters(in: .whitespacesAndNewlines)
                    let character = String(cleaned.prefix(1))

                    print("âœ… OpenAI Visionèªè­˜æˆåŠŸ: \(character)")

                    DispatchQueue.main.async {
                        completion(.success(character))
                    }
                } else {
                    print("âŒ JSONè§£æå¤±æ•—")
                    print("ğŸ“ ç”Ÿãƒ‡ãƒ¼ã‚¿: \(String(data: data, encoding: .utf8) ?? "nil")")
                    DispatchQueue.main.async {
                        completion(.failure(PhotoAnalyzerError.processingFailed))
                    }
                }
            } catch {
                print("âŒ JSONè§£æã‚¨ãƒ©ãƒ¼: \(error)")
                DispatchQueue.main.async {
                    completion(.failure(error))
                }
            }
        }

        task.resume()
    }

    // MARK: - Private Methods

    private func processObservations(_ observations: [VNRecognizedTextObservation], imageSize: CGSize) -> [RecognizedText] {
        print("\nğŸ”§ processObservationsé–‹å§‹ (\(observations.count)ä»¶)")
        var results: [RecognizedText] = []

        for (index, observation) in observations.enumerated() {
            guard let topCandidate = observation.topCandidates(1).first else {
                print("   é ˜åŸŸ \(index + 1): å€™è£œãªã— - ã‚¹ã‚­ãƒƒãƒ—")
                continue
            }

            // âœ… ä¿¡é ¼åº¦ãƒã‚§ãƒƒã‚¯ã‚’ç·©ãï¼ˆ0.1ä»¥ä¸Šï¼‰
            if topCandidate.confidence < 0.1 {
                print("   é ˜åŸŸ \(index + 1): [\(topCandidate.string)] ä¿¡é ¼åº¦ãŒéå¸¸ã«ä½ã„ï¼ˆ\(String(format: "%.3f", topCandidate.confidence))ï¼‰ - ã‚¹ã‚­ãƒƒãƒ—")
                continue
            }

            // âš ï¸ ä¿¡é ¼åº¦ãŒä½ã„å ´åˆã¯è­¦å‘Š
            if topCandidate.confidence < 0.5 {
                print("   é ˜åŸŸ \(index + 1): âš ï¸ [\(topCandidate.string)] ä¿¡é ¼åº¦ãŒä½ã„ï¼ˆ\(String(format: "%.3f", topCandidate.confidence))ï¼‰ãŒã€çµæœã«å«ã‚ã¾ã™")
            } else {
                print("   é ˜åŸŸ \(index + 1): âœ… [\(topCandidate.string)] ä¿¡é ¼åº¦: \(String(format: "%.3f", topCandidate.confidence))")
            }

            // ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’ç”»åƒåº§æ¨™ã«å¤‰æ›
            let boundingBox = observation.boundingBox
            let rect = VNImageRectForNormalizedRect(
                boundingBox,
                Int(imageSize.width),
                Int(imageSize.height)
            )

            let recognizedText = RecognizedText(
                text: topCandidate.string,
                confidence: topCandidate.confidence,
                boundingBox: rect
            )

            results.append(recognizedText)
        }

        print("ğŸ”§ processObservationså®Œäº†: \(results.count)ä»¶ã‚’è¿”ã—ã¾ã™")
        return results
    }
}

// MARK: - Models

/// èªè­˜ã•ã‚ŒãŸæ–‡å­—ã®æƒ…å ±
struct RecognizedText {
    let text: String
    let confidence: Float
    let boundingBox: CGRect

    var debugDescription: String {
        "Text: '\(text)', Confidence: \(String(format: "%.2f", confidence)), BBox: \(boundingBox)"
    }
}

/// æ–‡å­—ã¨å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹ã®ãƒšã‚¢
struct CharacterWithBounds {
    let text: String
    let boundingBox: CGRect
}

// MARK: - Errors

enum PhotoAnalyzerError: LocalizedError {
    case invalidImage
    case noTextFound
    case processingFailed

    var errorDescription: String? {
        switch self {
        case .invalidImage:
            return "ç”»åƒãŒç„¡åŠ¹ã§ã™"
        case .noTextFound:
            return "æ–‡å­—ãŒèªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸ"
        case .processingFailed:
            return "ç”»åƒå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ"
        }
    }
}
